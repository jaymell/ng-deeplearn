Hyperparameter Tuning
. alpha, learning rate, generally most important
. followed by:
 -- beta for momentum
 -- number hidden units
 -- mini-batch size
. followed by:
 -- number of layers
 -- learning rate decay
. almost never:
 -- beta_1 (0.9), beta_2 (0.999), epsilon (10e-8) in Adam

Random sampling
. formerly, 'grids' were common approach, but this would artificially
  limit number of observations on each tested hyperparam
. Course to fine -- drill in to progressively narrower ranges of values,
  continue random sampling within these narrower ranges
. appropriate scale
 -- random doesn't necessarily mean 'uniformly' at random
 -- if the scale of a particular parameter is logarithmic, you should
    sample uniformly on a logarithmic scale
    if expected range is 0.0001 to 1, don't uniformly sample between those;
    rather, sample evenly between 0.0001 and 0.001, 0.001 and 0.01, 0.01 and .1, .1 and 1
 -- in python:
   r = -4 * np.random.rand()
   var = 10**r


"Pandas" vs Caviar
. babysitting one model, testing various hyperparameters, vs
  testing lots of different models in parallel
. depends on available computing resources which approach is more feasible, but testing lots of models at once always preferable


Batch Normalization
. Normalizing the inputs (ie, z or a, usually z) of each layer of your network
. For layer l, feature i, compute mean, variance of z^[l]i, standard deviation
  -- mu = 1/m * Sigma(z^[l]i)
  -- sigma^2 = 1/m * Sigma(z^[l]i - mu)^2
  -- z_norm = z^[l]i - mu / sqrt( sigma^2 + e)
    -- e is added to avoid possible zero values in denominator
. You may not want mean of zero and variance of 1, though, so you use other learnable parameters, gamma and Beta, to control this
 -- ztilde^[l]i = gamma * z_norm + beta
 -- gamma and Beta are updated along w/ othe parameters as model is trained
. when using normalization, you don't need the bias term, as it's effectively
  eliminated anyway during mean subtraction; "Beta" plays this role
  -- so, to calculate z:
    z^[l] = W^[l]a^[l-1]
    calculate z_norm^[l]
    ztilde^[l] = gamma^[l] * z_norm^[l] + Beta^[l]
. dimensions of gamma and Beta are both (n^[l], l)
. normalization useful in part b/c it makes weights in later layers of the network
  robust to changes in earlier layers -- ie, dramatically different input values
  won't affect weights as much
. regularization effect:
  -- because mean and variance are computed on a given _mini batch_, you will get some
     noise in the activations that is somewhat like dropout
  -- nonetheless, you shouldn't use batch norm purely for the regularization effect
. using during testing
 -- basically, you need to maintain a running weighted average for mu and sigma^2
    that you can use during testing

